import json
import re
import os
import textwrap
from langchain_community.llms import Ollama
from tabulate import tabulate
from langchain_ollama import OllamaLLM

# ==============================================================================
# [ì„¤ì •]
FILENAME = "FuSaReq01.json" 
MODEL_NAME = "mistral"
# MODEL_NAME = "Ollama"          
# ==============================================================================

# [í•µì‹¬ ë³€ê²½] ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼, ê° Slotë³„ ìƒì„¸ í‰ê°€ ê¸°ì¤€ì„ ì •ì˜í•©ë‹ˆë‹¤.
IR_DEFINITIONS = {
    "Why": "The rationale or justification for the requirement. Does it explain 'Why' this function is needed for safety? (e.g., linked to Safety Goal)",
    "What": "The core function or action. Does it clearly describe 'What' the system shall do? (Subject + Action Verb)",
    "How type": "Qualitative or quantitative attributes of the action. Does it describe the 'manner' of operation? (e.g., forcefully, gradually, visually)",
    "When": "The trigger condition or state. Does it specify 'When' the action executes? (e.g., Pre-conditions, Triggers)",
    "Constraints": "Performance limits or bounds. Does it include specific values like FTTI, Latency, Voltage limits, or Tolerance?",
    "Verification": "How to verify this requirement. Is the requirement testable? Does it imply a verification method?",
    "Acceptance criteria": "The pass/fail criteria. What specific outcome defines success?",
    "Anchors": "References to other IDs, interfaces, or system elements. Are the inputs/outputs or related components clearly identified?"
}

# í‚¤ ë¦¬ìŠ¤íŠ¸ë§Œ ë”°ë¡œ ì¶”ì¶œ (ìˆœì„œ ë³´ì¥ìš©)
IR_SLOTS = list(IR_DEFINITIONS.keys())

class RequirementEvaluator:
    def __init__(self, model_name="mistral"):
        print(f"ğŸ¤– LLM ëª¨ë¸({model_name}) ë¡œë”© ì¤‘...")
        self.llm = Ollama(model=model_name)

    def clean_json_string(self, json_str):
        json_str = re.sub(r'```json\s*', '', json_str)
        json_str = re.sub(r'```\s*$', '', json_str)
        return json_str.strip()

    def evaluate(self, req_id, requirement_text):
        
        # [í•µì‹¬ ë³€ê²½] ë”•ì…”ë„ˆë¦¬ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ ë³€í™˜
        definitions_text = "\n".join([f"- {key}: {desc}" for key, desc in IR_DEFINITIONS.items()])

        prompt = f"""
        You are an Expert Requirements Engineer based on ISO 26262.
        
        Analyze the following requirement based on the 9 IR Slots defined below.
        You MUST follow the specific definitions provided for each slot to assign a score.
        You should provide the answer in Korean for every requirement and every slot.
        
        [Evaluation Rubric (Definitions)]:
        {definitions_text}

        [Scoring Criteria (1-5)]:
        1: Missing (The slot information is completely absent)
        2: Vague (Mentioned but very ambiguous or abstract)
        3: Average (Understandable but lacks specific details/values)
        4: Good (Clear, specific, and unambiguous)
        5: Excellent (Perfectly defined, quantified with tolerances where applicable)

        [Target Requirement]:
        ID: {req_id}
        Text: "{requirement_text}"

        [Output Format]:
        Output ONLY a valid JSON object. Do not explain outside the JSON.
        You must give the answer in Korean for every requirement and every slot.
        Keys must be exactly: {", ".join(IR_SLOTS)}
        
        Example:
        {{
            "Why": {{"score": 1, "reason": "No safety rationale or justification provided."}},
            "Constraints": {{"score": 5, "reason": "Specific timing constraint (500ms) is clearly defined."}}
        }}
        """

        try:
            response = self.llm.invoke(prompt)
            cleaned_response = self.clean_json_string(response)
            return json.loads(cleaned_response)
        except Exception as e:
            print(f"   âŒ í‰ê°€ ì‹¤íŒ¨ ({req_id}): {e}")
            return None

def load_requirements(filename):
    if not os.path.exists(filename):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
        return []
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
        req_list = []
        if isinstance(data, list):
            req_list = data
        elif isinstance(data, dict):
            for key in ["requirements", "reqs", "data", "items"]:
                if key in data and isinstance(data[key], list):
                    req_list = data[key]
                    break
            if not req_list:
                req_list = [data]
        return req_list
    except Exception as e:
        print(f"âŒ JSON ë¡œë“œ ì—ëŸ¬: {e}")
        return []

def extract_text_and_id(item, index):
    req_id = item.get("id") or item.get("req_id") or item.get("ID") or f"REQ_{index+1}"
    text = item.get("text") or item.get("requirement") or item.get("description") or item.get("raw_text")
    if isinstance(item, str):
        text = item
        req_id = f"REQ_{index+1}"
    return req_id, text

def print_results(req_id, text, results):
    if not results: return

    table_data = []
    total_score = 0
    
    RESET = "\033[0m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    RED = "\033[91m"
    CYAN = "\033[96m"
    BOLD = "\033[1m"

    for slot in IR_SLOTS:
        data = results.get(slot, {"score": 0, "reason": "N/A"})
        score = data['score']
        reason = data['reason']
        total_score += score
        
        if score >= 4: s_disp = f"{GREEN}{score}{RESET}"
        elif score >= 3: s_disp = f"{YELLOW}{score}{RESET}"
        else: s_disp = f"{RED}{score}{RESET}"
        
        wrapped_reason = "\n".join(textwrap.wrap(reason, width=60))
        table_data.append([slot, s_disp, wrapped_reason])

    print("\n" + "="*80)
    print(f"ğŸ“„ {BOLD}ìš”êµ¬ì‚¬í•­ ì›ë¬¸ ë¶„ì„ ê²°ê³¼{RESET}")
    print("="*80)
    print(f"ğŸ†” {CYAN}ID:{RESET} {req_id}")
    print(f"ğŸ“ {CYAN}Text:{RESET}\n")
    print(f"   \"{text}\"")
    print("-" * 80)
    print(tabulate(table_data, headers=["IR Slot", "Score", "Evaluation Reason"], tablefmt="grid"))
    
    avg_score = total_score / len(IR_SLOTS)
    print(f"\nğŸ“ˆ {BOLD}ì¢…í•© í‰ê·  ì ìˆ˜: {avg_score:.2f} / 5.0{RESET}")
    print("="*80 + "\n")

# --- ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    print(f"ğŸ“‚ '{FILENAME}' ë¡œë“œ ì¤‘...")
    requirements = load_requirements(FILENAME)
    
    if not requirements:
        print("ë°ì´í„° ì—†ìŒ.")
        exit()

    evaluator = RequirementEvaluator(model_name=MODEL_NAME)

    for idx, item in enumerate(requirements):
        r_id, r_text = extract_text_and_id(item, idx)
        
        if not r_text:
            continue

        print(f"\nğŸ”„ [Progress]: {idx+1}/{len(requirements)} ë¶„ì„ ì¤‘...")
        # ì›ë³¸ ë°ì´í„°ëŠ” ë„ˆë¬´ ê¸¸ë©´ ìƒëµ ê°€ëŠ¥, í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
        # print(f"ğŸ“¥ [Raw Input]: {json.dumps(item, ensure_ascii=False)}")
        
        results = evaluator.evaluate(r_id, r_text)
        print_results(r_id, r_text, results)